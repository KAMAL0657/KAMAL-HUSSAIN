{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KAMAL0657/KAMAL-HUSSAIN/blob/main/reco_monitoring_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f98c24ec",
      "metadata": {
        "id": "f98c24ec"
      },
      "source": [
        "# Recommendation Monitoring & Maintenance Demo (Colab-ready)\n",
        "This single Colab notebook simulates a recommendation service and demonstrates a monitoring + maintenance loop:\n",
        "- Train a simple PyTorch classifier to predict click probability (serves as \"recommender score\").\n",
        "- Start a FastAPI server that returns predictions and logs audit events.\n",
        "- Simulate production traffic, including **feature drift** and a **new user segment** appearing over time.\n",
        "- Continuously compute business metrics (CTR), detect distributional drift (KS test and JS divergence), and raise alerts.\n",
        "- When alerts fire, automatically **retrain** the model on recent data, run a **shadow / canary** evaluation, and decide whether to promote or rollback.\n",
        "\n",
        "\n",
        "Run all cells in order. The notebook uses CPU-only libraries and runs servers locally inside Colab.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "15111000",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15111000",
        "outputId": "ca51cba6-67c2-4dc0-c984-74e1b79f7c1b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== ALERTS TRIGGERED === [('FEATURE_DRIFT_HIGH', 2.0)] ctr=1.000 js=0.000 drift_mean=2.000\n",
            "\n",
            "=== ALERTS TRIGGERED === [('FEATURE_DRIFT_HIGH', 2.0)] ctr=1.000 js=0.000 drift_mean=2.000\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install -q torch torchvision --extra-index-url https://download.pytorch.org/whl/cpu\n",
        "!pip install -q fastapi uvicorn[standard] httpx nest-asyncio scikit-learn scipy numpy pandas matplotlib\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8363e1e5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8363e1e5",
        "outputId": "e0165422-e0d4-4ec3-8a20-5102ed1e4b11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0 train_loss=0.6971 val_mse=0.24952\n",
            "epoch 2 train_loss=0.6938 val_mse=0.24857\n",
            "epoch 4 train_loss=0.6919 val_mse=0.24815\n",
            "epoch 6 train_loss=0.6909 val_mse=0.24805\n",
            "epoch 8 train_loss=0.6905 val_mse=0.24813\n",
            "Initial model and scaler saved to /content/reco_model\n"
          ]
        }
      ],
      "source": [
        "# Create synthetic training data and train a simple PyTorch logistic model\n",
        "import torch, torch.nn as nn, numpy as np, random, os, json\n",
        "from sklearn.model_selection import train_test_split\n",
        "import math\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "\n",
        "def generate_users(n, new_segment=False, drift_level=0.0):\n",
        "    # features: [age, recency, activity_score, feature_drifted]\n",
        "    ages = np.random.normal(35 + (5 if new_segment else 0), 10, size=n)  # new segment older\n",
        "    recency = np.random.exponential(scale=10.0, size=n)  # days since last\n",
        "    activity = np.random.beta(2,5,size=n) * 10\n",
        "    # drifted feature: baseline centered at 0, but drift shifts mean\n",
        "    drifted = np.random.normal(loc=drift_level, scale=1.0, size=n)\n",
        "    X = np.vstack([ages, recency, activity, drifted]).T.astype(np.float32)\n",
        "    # click probability simulated\n",
        "    logits = -0.05*(ages-30) - 0.1*np.log1p(recency) + 0.4*activity + 1.5*drifted\n",
        "    probs = 1/(1+np.exp(-logits/10.0))  # scale down to reasonable probs\n",
        "    y = (np.random.rand(n) < probs).astype(np.float32)\n",
        "    return X, y, probs\n",
        "\n",
        "# initial training data (no new segment, no drift)\n",
        "X0, y0, p0 = generate_users(20000, new_segment=False, drift_level=0.0)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler().fit(X0)\n",
        "X0s = scaler.transform(X0)\n",
        "\n",
        "# simple PyTorch model (small MLP)\n",
        "class SimpleReco(nn.Module):\n",
        "    def __init__(self, in_dim=4):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, 16),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(16, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x).squeeze(-1)\n",
        "\n",
        "model = SimpleReco(4)\n",
        "criterion = nn.BCELoss()\n",
        "opt = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# train\n",
        "Xtrain, Xval, ytrain, yval = train_test_split(X0s, y0, test_size=0.2, random_state=SEED)\n",
        "Xtrain_t = torch.tensor(Xtrain, dtype=torch.float32)\n",
        "ytrain_t = torch.tensor(ytrain, dtype=torch.float32)\n",
        "Xval_t = torch.tensor(Xval, dtype=torch.float32)\n",
        "yval_t = torch.tensor(yval, dtype=torch.float32)\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    preds = model(Xtrain_t)\n",
        "    loss = criterion(preds, ytrain_t)\n",
        "    opt.zero_grad(); loss.backward(); opt.step()\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        v = model(Xval_t).numpy()\n",
        "        val_loss = ((v - yval_t.numpy())**2).mean()\n",
        "    if epoch%2==0:\n",
        "        print(f'epoch {epoch} train_loss={loss.item():.4f} val_mse={val_loss:.5f}')\n",
        "\n",
        "# save model and scaler\n",
        "os.makedirs('/content/reco_model', exist_ok=True)\n",
        "torch.jit.save(torch.jit.trace(model, torch.randn(1,4)), '/content/reco_model/model.ts')\n",
        "import pickle\n",
        "with open('/content/reco_model/scaler.pkl','wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "\n",
        "print('Initial model and scaler saved to /content/reco_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e8b99e00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8b99e00",
        "outputId": "3c544803-4359-42f6-a210-733bad68657f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastAPI server running at http://127.0.0.1:8000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [157]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n"
          ]
        }
      ],
      "source": [
        "# Start a FastAPI server that serves /predict and logs audit events to a local file.\n",
        "import threading, nest_asyncio, uvicorn, json, time, uuid, hashlib, pickle\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "import torch, numpy as np, os, logging\n",
        "nest_asyncio.apply()\n",
        "\n",
        "MODEL_PATH = '/content/reco_model/model.ts'\n",
        "SCALER_PATH = '/content/reco_model/scaler.pkl'\n",
        "AUDIT_LOG = '/content/reco_audit.log'\n",
        "\n",
        "model = torch.jit.load(MODEL_PATH, map_location='cpu')\n",
        "model.eval()\n",
        "with open(SCALER_PATH,'rb') as f:\n",
        "    scaler = pickle.load(f)\n",
        "\n",
        "app = FastAPI()\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger('reco-api')\n",
        "\n",
        "class Req(BaseModel):\n",
        "    features: list\n",
        "    user_segment: str = 'existing'  # 'existing' or 'new'\n",
        "\n",
        "def hash_input(x):\n",
        "    return hashlib.sha256(json.dumps(x).encode()).hexdigest()[:16]\n",
        "\n",
        "@app.post('/predict')\n",
        "async def predict(req: Req):\n",
        "    req_id = str(uuid.uuid4())\n",
        "    t0 = time.time()\n",
        "    x = np.array(req.features, dtype=float).reshape(1,-1)\n",
        "    xs = scaler.transform(x)\n",
        "    xt = torch.tensor(xs, dtype=torch.float32)\n",
        "    with torch.no_grad():\n",
        "        score = float(model(xt).item())\n",
        "    latency_ms = int((time.time()-t0)*1000)\n",
        "    label = 1 if score>0.5 else 0\n",
        "    # write audit (append-only)\n",
        "    audit = {'request_id': req_id, 'ts': time.time(), 'features_hash': hash_input(req.features),\n",
        "             'user_segment': req.user_segment, 'score': score, 'served_model': 'baseline'}\n",
        "    with open(AUDIT_LOG,'a') as f:\n",
        "        f.write(json.dumps(audit)+'\\n')\n",
        "    return {'score':score, 'request_id': req_id, 'latency_ms': latency_ms}\n",
        "\n",
        "def run_server():\n",
        "    uvicorn.run(app, host='127.0.0.1', port=8000, log_level='info')\n",
        "\n",
        "threading.Thread(target=run_server, daemon=True).start()\n",
        "print('FastAPI server running at http://127.0.0.1:8000')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "88c4b41e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88c4b41e",
        "outputId": "d2994f90-ffb7-4eb0-c1ae-b53a80ca1b33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:    [Errno 98] error while attempting to bind on address ('127.0.0.1', 8000): address already in use\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traffic simulator started (runs ~90s). Check /content/sim_metrics.jsonl and /content/reco_audit.log\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n"
          ]
        }
      ],
      "source": [
        "# Simulate traffic in a background task. We'll progressively introduce drift and a new user segment.\n",
        "import asyncio, httpx, random, time, threading, json, math, os\n",
        "SIM_LOG = '/content/sim_metrics.jsonl'\n",
        "if os.path.exists(SIM_LOG):\n",
        "    os.remove(SIM_LOG)\n",
        "\n",
        "async def hit_once(client, features, segment='existing'):\n",
        "    try:\n",
        "        r = await client.post('http://127.0.0.1:8000/predict', json={'features':features.tolist(), 'user_segment': segment}, timeout=5.0)\n",
        "        if r.status_code==200:\n",
        "            return True, r.json()['score']\n",
        "        return False, None\n",
        "    except Exception as e:\n",
        "        return False, None\n",
        "\n",
        "def stream_traffic(duration_seconds=60, qps=50, drift_schedule=None):\n",
        "    \"\"\"Simulate traffic for duration_seconds at approx qps.\n",
        "    drift_schedule: list of tuples (time_offset_seconds, drift_level, pct_new_segment)\n",
        "    \"\"\"\n",
        "    import asyncio, time, httpx, numpy as np\n",
        "    start = time.time()\n",
        "    loop = asyncio.new_event_loop(); asyncio.set_event_loop(loop)\n",
        "    async def runner():\n",
        "        async with httpx.AsyncClient() as client:\n",
        "            next_drift_idx = 0\n",
        "            drift_level = 0.0\n",
        "            pct_new = 0.0\n",
        "            while time.time() - start < duration_seconds:\n",
        "                t = time.time() - start\n",
        "                # update drift/segment according to schedule\n",
        "                if drift_schedule and next_drift_idx < len(drift_schedule) and t >= drift_schedule[next_drift_idx][0]:\n",
        "                    _, drift_level, pct_new = drift_schedule[next_drift_idx]\n",
        "                    next_drift_idx += 1\n",
        "                tasks = []\n",
        "                for i in range(qps):\n",
        "                    # decide if new user\n",
        "                    if random.random() < pct_new:\n",
        "                        seg=True\n",
        "                    else:\n",
        "                        seg=False\n",
        "                    # generate features reflecting drift and segment\n",
        "                    ages = np.random.normal(35 + (5 if seg else 0), 10)\n",
        "                    recency = np.random.exponential(scale=10.0)\n",
        "                    activity = np.random.beta(2,5)*10\n",
        "                    drifted = np.random.normal(loc=drift_level, scale=1.0)\n",
        "                    features = np.array([ages, recency, activity, drifted], dtype=float)\n",
        "                    tasks.append(asyncio.create_task(hit_once(client, features, 'new' if seg else 'existing')))\n",
        "                results = await asyncio.gather(*tasks)\n",
        "                # log metrics of this second\n",
        "                succ = sum(1 for s,_ in results if s)\n",
        "                avg_score = sum((sc for s,sc in results if s)) / max(1, succ)\n",
        "                with open(SIM_LOG,'a') as f:\n",
        "                    f.write(json.dumps({'t': time.time(), 'succ': succ, 'qps': qps, 'avg_score': avg_score, 'drift': drift_level, 'pct_new': pct_new})+'\\n')\n",
        "                await asyncio.sleep(1.0)\n",
        "    loop.run_until_complete(runner())\n",
        "\n",
        "# Run simulator in background thread with scheduled drift events\n",
        "schedule = [\n",
        "    (0, 0.0, 0.0),        # start: no drift, no new segment\n",
        "    (15, 0.5, 0.0),       # after 15s, small drift begins\n",
        "    (30, 1.2, 0.05),      # after 30s, stronger drift + 5% new segment\n",
        "    (45, 1.5, 0.15),      # after 45s, more drift + 15% new users\n",
        "    (60, 2.0, 0.30)       # after 60s, heavy drift + 30% new users\n",
        "]\n",
        "\n",
        "threading.Thread(target=stream_traffic, args=(90, 30, schedule), daemon=True).start()\n",
        "print('Traffic simulator started (runs ~90s). Check /content/sim_metrics.jsonl and /content/reco_audit.log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2dd93d83",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dd93d83",
        "outputId": "d6fc7c1a-ba09-4c38-e5f4-24a67feadfc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Monitoring started (will run ~100s).\n"
          ]
        }
      ],
      "source": [
        "# Monitoring loop: periodically read simulator and audit logs, compute CTR and drift metrics, and trigger actions.\n",
        "import time, json, threading, os, math\n",
        "from scipy import stats\n",
        "from collections import deque, defaultdict\n",
        "import numpy as np\n",
        "\n",
        "ALERTS = []\n",
        "ACTION_LOG = []\n",
        "\n",
        "def read_sim_metrics():\n",
        "    path = '/content/sim_metrics.jsonl'\n",
        "    if not os.path.exists(path): return []\n",
        "    with open(path) as f:\n",
        "        lines = [json.loads(l) for l in f if l.strip()]\n",
        "    return lines\n",
        "\n",
        "def read_audit_logs():\n",
        "    path = '/content/reco_audit.log'\n",
        "    if not os.path.exists(path): return []\n",
        "    with open(path) as f:\n",
        "        lines = [json.loads(l) for l in f if l.strip()]\n",
        "    return lines\n",
        "\n",
        "# utility: compute JS divergence between two histograms\n",
        "def js_divergence(p, q):\n",
        "    # p, q are arrays (prob masses) summing to 1\n",
        "    p = np.array(p); q = np.array(q)\n",
        "    m = 0.5*(p+q)\n",
        "    def kl(a,b):\n",
        "        a = np.where(a==0, 1e-12, a)\n",
        "        b = np.where(b==0, 1e-12, b)\n",
        "        return np.sum(a * np.log(a/b))\n",
        "    return 0.5*(kl(p,m) + kl(q,m))\n",
        "\n",
        "# baseline distribution (from training predictions)\n",
        "# collect training scores histogram\n",
        "train_scores = []\n",
        "with open('/content/reco_audit.log','w') as f: f.write('')  # clear audit at start\n",
        "# generate baseline scores by passing training set through model\n",
        "import pickle, torch, numpy as np\n",
        "scaler = pickle.load(open('/content/reco_model/scaler.pkl','rb'))\n",
        "model = torch.jit.load('/content/reco_model/model.ts', map_location='cpu')\n",
        "model.eval()\n",
        "X_train = np.vstack([np.random.normal(35,10,1000), np.random.exponential(10,1000),\n",
        "                     np.random.beta(2,5,1000)*10, np.random.normal(0,1,1000)]).T\n",
        "X_train_s = scaler.transform(X_train)\n",
        "with torch.no_grad():\n",
        "    import torch as _t\n",
        "    s = model(_t.tensor(X_train_s,dtype=_t.float32)).numpy()\n",
        "train_scores = s.tolist()\n",
        "hist_bins = np.linspace(0,1,21)\n",
        "train_hist, _ = np.histogram(train_scores, bins=hist_bins)\n",
        "train_hist = train_hist / train_hist.sum()\n",
        "\n",
        "# monitoring thread\n",
        "def monitor_loop(duration=95, check_interval=5):\n",
        "    start = time.time()\n",
        "    triggered_retrain = False\n",
        "    while time.time() - start < duration:\n",
        "        time.sleep(check_interval)\n",
        "        sim = read_sim_metrics()\n",
        "        audit = read_audit_logs()\n",
        "        # compute recent CTR approximation using simulator metrics succ/qps per second\n",
        "        if sim:\n",
        "            last10 = sim[-10:]\n",
        "            total_requests = sum(s['qps'] for s in last10)\n",
        "            total_succ = sum(s['succ'] for s in last10)\n",
        "            ctr = total_succ / max(1, total_requests)\n",
        "        else:\n",
        "            ctr = 0.0\n",
        "        # compute current score histogram from audit logs (last N)\n",
        "        scores = [e['score'] for e in audit[-200:]] if audit else []\n",
        "        if scores:\n",
        "            cur_hist, _ = np.histogram(scores, bins=hist_bins)\n",
        "            if cur_hist.sum()>0:\n",
        "                cur_hist = cur_hist / cur_hist.sum()\n",
        "                js = js_divergence(train_hist, cur_hist)\n",
        "            else:\n",
        "                js = 0.0\n",
        "        else:\n",
        "            js = 0.0\n",
        "        # univariate drift check on drifted feature by sampling recent generated features via sim metrics (we logged drift level)\n",
        "        drift_levels = [s['drift'] for s in sim[-20:]] if sim else []\n",
        "        drift_mean = np.mean(drift_levels) if drift_levels else 0.0\n",
        "        # simple alert conditions\n",
        "        alerts_now = []\n",
        "        if ctr < 0.20:  # example threshold\n",
        "            alerts_now.append(('CTR_DROP', ctr))\n",
        "        if js > 0.15:\n",
        "            alerts_now.append(('PRED_DIST_SHIFT_JS', js))\n",
        "        if drift_mean > 1.0:\n",
        "            alerts_now.append(('FEATURE_DRIFT_HIGH', float(drift_mean)))\n",
        "        if alerts_now:\n",
        "            ALERTS.append({'t': time.time(), 'alerts': alerts_now, 'ctr': ctr, 'js': js, 'drift_mean': drift_mean})\n",
        "            print('\\n=== ALERTS TRIGGERED ===', alerts_now, f'ctr={ctr:.3f}', f'js={js:.3f}', f'drift_mean={drift_mean:.3f}')\n",
        "        else:\n",
        "            print(f'no alerts. ctr={ctr:.3f}, js={js:.3f}, drift_mean={drift_mean:.3f}')\n",
        "        # If persistent alerts and not yet triggered retrain, trigger retrain\n",
        "        if alerts_now and not triggered_retrain:\n",
        "            print('Triggering automated retrain based on alerts...')\n",
        "            ACTION_LOG.append({'t':time.time(),'action':'trigger_retrain','reason':alerts_now})\n",
        "            triggered_retrain = True\n",
        "            # perform retrain in background\n",
        "            threading.Thread(target=retrain_and_canary, daemon=True).start()\n",
        "    print('\\nMonitoring finished. Alerts collected:', len(ALERTS))\n",
        "\n",
        "# We'll define retrain_and_canary next (but monitor will use it)\n",
        "def retrain_and_canary():\n",
        "    print('\\n[Retrain] collecting recent labeled data and retraining model...')\n",
        "    # For demo, we'll synthesize new training data emphasizing recent drift and new segment\n",
        "    import numpy as np, torch, pickle, random\n",
        "    # generate data with drift and new segment presence\n",
        "    X_new, y_new, _ = [], [], []\n",
        "    for i in range(10000):\n",
        "        if random.random() < 0.25:\n",
        "            # new segment\n",
        "            X,y,_p = generate_users(1, new_segment=True, drift_level=1.5)\n",
        "        else:\n",
        "            X,y,_p = generate_users(1, new_segment=False, drift_level=1.0)\n",
        "        X_new.append(X[0]); y_new.append(y[0])\n",
        "    X_new = np.vstack(X_new).astype(np.float32)\n",
        "    y_new = np.array(y_new).astype(np.float32)\n",
        "    # combine with a fraction of old data for stability\n",
        "    X_comb = np.vstack([X0[:5000], X_new])\n",
        "    y_comb = np.concatenate([y0[:5000], y_new])\n",
        "    # scale with original scaler refit\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    scaler2 = StandardScaler().fit(X_comb)\n",
        "    Xs = scaler2.transform(X_comb)\n",
        "    # train new PyTorch model\n",
        "    import torch.nn as nn, torch.optim as optim\n",
        "    model_new = SimpleReco(4)\n",
        "    opt = optim.Adam(model_new.parameters(), lr=0.01)\n",
        "    Xt = torch.tensor(Xs, dtype=torch.float32)\n",
        "    yt = torch.tensor(y_comb, dtype=torch.float32)\n",
        "    for epoch in range(8):\n",
        "        model_new.train()\n",
        "        preds = model_new(Xt)\n",
        "        loss = nn.BCELoss()(preds, yt)\n",
        "        opt.zero_grad(); loss.backward(); opt.step()\n",
        "    # save new model and scaler to /content/reco_model_new\n",
        "    import os, pickle, torch as _t\n",
        "    os.makedirs('/content/reco_model_new', exist_ok=True)\n",
        "    _t.jit.save(_t.jit.trace(model_new, _t.randn(1,4)), '/content/reco_model_new/model.ts')\n",
        "    with open('/content/reco_model_new/scaler.pkl','wb') as f:\n",
        "        pickle.dump(scaler2, f)\n",
        "    print('[Retrain] new model saved. Running shadow evaluation...')\n",
        "    # shadow: evaluate new model vs baseline on a recent sample of requests (simulate using current drift levels)\n",
        "    # load baseline and new model\n",
        "    baseline = torch.jit.load('/content/reco_model/model.ts', map_location='cpu')\n",
        "    baseline.eval()\n",
        "    newm = _t.jit.load('/content/reco_model_new/model.ts', map_location='cpu')\n",
        "    newm.eval()\n",
        "    # sample 2000 recent users with drift and new segment presence\n",
        "    import numpy as np, random\n",
        "    Xsample, ysample = generate_users(2000, new_segment=False, drift_level=1.2)\n",
        "    # 20% new segment inserted\n",
        "    n = Xsample.shape[0]\n",
        "    idx_new = np.random.choice(n, size=int(0.2*n), replace=False)\n",
        "    for i in idx_new:\n",
        "        Xsample[i], _, _ = generate_users(1, new_segment=True, drift_level=1.5)\n",
        "    # scale via scaler2 to run both through comparable features for new model, but baseline expects original scaler;\n",
        "    # to be fair, transform with original scaler for baseline and scaler2 for new model.\n",
        "    s_baseline = pickle.load(open('/content/reco_model/scaler.pkl','rb'))\n",
        "    Xb = s_baseline.transform(Xsample)\n",
        "    Xn = scaler2.transform(Xsample)\n",
        "    import torch as _t\n",
        "    with torch.no_grad():\n",
        "        sb = baseline(_t.tensor(Xb, dtype=_t.float32)).numpy()\n",
        "        sn = newm(_t.tensor(Xn, dtype=_t.float32)).numpy()\n",
        "    ctr_baseline = (sb>0.5).mean()  # proxy: fraction of positives\n",
        "    ctr_new = (sn>0.5).mean()\n",
        "    print(f'[Shadow Eval] baseline positive-rate(proxy)={ctr_baseline:.3f} new={ctr_new:.3f}')\n",
        "    ACTION_LOG.append({'t':time.time(),'action':'shadow_eval','baseline_pos':float(ctr_baseline),'new_pos':float(ctr_new)})\n",
        "    # Simple canary decision: choose model with higher positive rate on recent sample\n",
        "    promote = ctr_new >= ctr_baseline\n",
        "    if promote:\n",
        "        print('[Canary] New model looks better in shadow — promoting to canary traffic (simulated)...')\n",
        "        ACTION_LOG.append({'t':time.time(),'action':'promote_canary'})\n",
        "        # simulate canary: route 10% traffic to new model for 30s and compare observed CTR (proxy)\n",
        "        baseline_ctr_obs, new_ctr_obs = simulate_canary(duration=30, pct_new=0.1, model_new='/content/reco_model_new/model.ts', scaler_new='/content/reco_model_new/scaler.pkl')\n",
        "        print(f'[Canary] observed ctr baseline={baseline_ctr_obs:.3f}, new={new_ctr_obs:.3f}')\n",
        "        ACTION_LOG.append({'t':time.time(),'action':'canary_result','base':baseline_ctr_obs,'new':new_ctr_obs})\n",
        "        # decision rule\n",
        "        if new_ctr_obs >= baseline_ctr_obs:\n",
        "            print('[Canary] Accepting new model — swap production model (for demo: replace baseline files)')\n",
        "            import shutil, os\n",
        "            shutil.rmtree('/content/reco_model')\n",
        "            os.rename('/content/reco_model_new','/content/reco_model')\n",
        "            ACTION_LOG.append({'t':time.time(),'action':'promote_final'})\n",
        "        else:\n",
        "            print('[Canary] Canary underperformed — rollback and keep baseline.')\n",
        "            ACTION_LOG.append({'t':time.time(),'action':'rollback'})\n",
        "\n",
        "    else:\n",
        "        print('[Shadow Eval] New model did not improve — aborting promotion.')\n",
        "        ACTION_LOG.append({'t':time.time(),'action':'abort_promote'})\n",
        "\n",
        "# simulate_canary function used above\n",
        "def simulate_canary(duration=30, pct_new=0.1, model_new=None, scaler_new=None):\n",
        "    # run a short traffic sim where pct_new of traffic goes to new model; compare observed positive rates (proxy CTR)\n",
        "    import time, random, numpy as np, pickle, torch\n",
        "    start = time.time()\n",
        "    t_end = start + duration\n",
        "    # load models\n",
        "    baseline = torch.jit.load('/content/reco_model/model.ts', map_location='cpu'); baseline.eval()\n",
        "    if model_new:\n",
        "        newm = torch.jit.load(model_new, map_location='cpu'); newm.eval()\n",
        "        s_new = pickle.load(open(scaler_new,'rb'))\n",
        "    s_baseline = pickle.load(open('/content/reco_model/scaler.pkl','rb'))\n",
        "    counts = {'base_pos':0,'base_tot':0,'new_pos':0,'new_tot':0}\n",
        "    while time.time() < t_end:\n",
        "        # generate a small batch per second\n",
        "        for _ in range(50):\n",
        "            seg = random.random() < 0.25\n",
        "            if seg:\n",
        "                X,_,_ = generate_users(1, new_segment=True, drift_level=1.5)\n",
        "            else:\n",
        "                X,_,_ = generate_users(1, new_segment=False, drift_level=1.2)\n",
        "            # decide routing\n",
        "            if random.random() < pct_new:\n",
        "                # to new model\n",
        "                Xn = s_new.transform(X)\n",
        "                with torch.no_grad():\n",
        "                    s = float(newm(torch.tensor(Xn,dtype=torch.float32)).item())\n",
        "                counts['new_tot'] += 1\n",
        "                counts['new_pos'] += int(s>0.5)\n",
        "            else:\n",
        "                Xb = s_baseline.transform(X)\n",
        "                with torch.no_grad():\n",
        "                    s = float(baseline(torch.tensor(Xb,dtype=torch.float32)).item())\n",
        "                counts['base_tot'] += 1\n",
        "                counts['base_pos'] += int(s>0.5)\n",
        "        time.sleep(1)\n",
        "    base_ctr = counts['base_pos']/max(1,counts['base_tot'])\n",
        "    new_ctr = counts['new_pos']/max(1,counts['new_tot'])\n",
        "    return base_ctr, new_ctr\n",
        "\n",
        "# start monitor thread\n",
        "threading.Thread(target=monitor_loop, kwargs={'duration':100,'check_interval':5}, daemon=True).start()\n",
        "print('Monitoring started (will run ~100s).')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f8983a9",
      "metadata": {
        "id": "0f8983a9"
      },
      "source": [
        "## After running the notebook\n",
        "- Watch stdout to see alerts, retrain, shadow evaluation, and canary results.\n",
        "- Files produced:\n",
        "  - `/content/reco_audit.log` : per-request audit entries (JSONL)\n",
        "  - `/content/sim_metrics.jsonl` : traffic simulator per-second metrics\n",
        "  - `/content/reco_model/` : current production model files (TorchScript + scaler)\n",
        "  - `/content/reco_model_new/` : retrained candidate (if produced)\n",
        "  - ACTION_LOG and ALERTS are in memory; view them by running cells to print them.\n",
        "\n",
        "\n",
        "### Helpful commands\n",
        "- Tail logs: `!tail -n 50 /content/reco_audit.log`\n",
        "- See simulator metrics: `!tail -n 50 /content/sim_metrics.jsonl`\n",
        "- List models: `!ls -la /content/reco_model*`\n",
        "\n",
        "This demo is simplified but illustrates the core monitoring → detect → retrain → canary → promote/rollback loop you can run in production.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}